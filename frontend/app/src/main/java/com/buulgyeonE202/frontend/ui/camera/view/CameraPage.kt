package com.buulgyeonE202.frontend.ui.camera.view

import LockScreenOrientation
import android.Manifest
import android.graphics.Bitmap
import android.graphics.Matrix
import android.util.Log
import androidx.activity.compose.rememberLauncherForActivityResult
import androidx.activity.result.contract.ActivityResultContracts
import androidx.camera.core.ImageAnalysis
import androidx.compose.foundation.gestures.detectTransformGestures
import androidx.compose.foundation.layout.*
import androidx.compose.material3.Scaffold
import androidx.compose.runtime.*
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.input.pointer.pointerInput
import androidx.compose.ui.platform.LocalContext
import androidx.compose.ui.unit.dp
import androidx.compose.ui.viewinterop.AndroidView
import androidx.hilt.navigation.compose.hiltViewModel
import androidx.lifecycle.viewmodel.compose.viewModel
import androidx.navigation.NavController
import com.buulgyeonE202.frontend.ui.component.MainBottomBar
import com.buulgyeonE202.frontend.ui.camera.component.CameraControlsBar
import com.buulgyeonE202.frontend.ui.camera.component.CameraPreview
import com.buulgyeonE202.frontend.ui.camera.component.rememberCameraRecorderController
import com.buulgyeonE202.frontend.ui.camera.viewmodel.CameraIntent
import com.buulgyeonE202.frontend.ui.camera.viewmodel.CameraViewModel
import kotlinx.coroutines.delay
import android.content.pm.ActivityInfo
import rememberDeviceRotation

// AI ê´€ë ¨ import
import java.util.concurrent.Executors
import com.buulgyeonE202.frontend.ui.ai.AiViewModel
import com.buulgyeonE202.frontend.ui.ai.GestureRecognizerHelper
import com.buulgyeonE202.frontend.data.manager.HumanTrackingManager
import com.buulgyeonE202.frontend.ui.ai.OverlayView
import com.buulgyeonE202.frontend.ui.ai.PoseLandmarkerHelper
import com.buulgyeonE202.frontend.ui.ai.TrackingOverlayView
import com.google.mediapipe.tasks.vision.gesturerecognizer.GestureRecognizerResult
import com.buulgyeonE202.frontend.ui.camera.model.LensFacing
import android.hardware.camera2.CameraCharacteristics // Camera2 ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
// CameraXì™€ Camera2ë¥¼ ì—°ê²°í•´ì£¼ëŠ” ì¸í„°ëŸ½ ë¼ì´ë¸ŒëŸ¬ë¦¬
import androidx.camera.camera2.interop.Camera2CameraInfo
import androidx.camera.camera2.interop.ExperimentalCamera2Interop
import androidx.annotation.OptIn

// [ë°±ìˆ˜ì—°] ë¹„íŠ¸ë§µ ë””ë²„ê¹…ìš© í…ŒìŠ¤íŠ¸ ëë‚˜ë©´ ê¼­ ì§€ìš¸ê²ƒ
//import java.io.File
//import java.io.FileOutputStream

@Composable
fun CameraPage(
    navController: NavController,
    modifier: Modifier = Modifier,
    cameraViewModel: CameraViewModel = viewModel(),
    aiViewModel: AiViewModel = hiltViewModel(),
    humanTrackingManager: HumanTrackingManager = hiltViewModel()
) {
    val uiRotation = rememberDeviceRotation()
    LockScreenOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT)

    val context = LocalContext.current
    val state by cameraViewModel.state.collectAsState()
    val recorderController = rememberCameraRecorderController()

    // ê²°ê³¼ ì‹œê°í™” ìƒíƒœ
    var latestGestureResult by remember { mutableStateOf<GestureRecognizerResult?>(null) }
    var gestureImgW by remember { mutableIntStateOf(0) }
    var gestureImgH by remember { mutableIntStateOf(0) }
    var gestureRotatedImgW by remember { mutableIntStateOf(0) }
    var gestureRotatedImgH by remember { mutableIntStateOf(0) }
    var Imgrotation by remember { mutableIntStateOf(0) } // [ë°±ìˆ˜ì—°] ê°ë„
    var gestureAppliedRotation by remember { mutableIntStateOf(0) } // ê²°ê³¼ì— ì ìš©ëœ íšŒì „ê°’
    val trackingState by humanTrackingManager.trackingState.collectAsState()

    // ë£°ëŸ¬ UI ìƒíƒœ
    var showRuler by remember { mutableStateOf(false) }
    var lastInteractionTime by remember { mutableLongStateOf(0L) }

    LaunchedEffect(lastInteractionTime) {
        if (!showRuler) return@LaunchedEffect
        delay(2000L)
        if (System.currentTimeMillis() - lastInteractionTime >= 2000L) {
            showRuler = false
        }
    }
    fun triggerRuler() { showRuler = true; lastInteractionTime = System.currentTimeMillis() }

    var hasCameraPermission by remember { mutableStateOf(false) }
    var hasAudioPermission by remember { mutableStateOf(false) }
    val isRecordingState = rememberUpdatedState(state.isRecording)

    // AI í—¬í¼ë“¤ ì´ˆê¸°í™”
    // ì œìŠ¤ì²˜ ì¸ì‹ì— ì‚¬ìš©ëœ íšŒì „ê°’ì„ ìº¡ì²˜ (ë¹„ë™ê¸° ê²°ê³¼ì™€ ë§¤ì¹­ìš©)
    var lastSentRotation by remember { mutableIntStateOf(0) }

    val gestureRecognizerHelper = remember {
        GestureRecognizerHelper(context) { result, _, _ ->
            // ğŸš¨ ì•ˆì „ì¥ì¹˜: ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚˜ë©´ AI íŒŒì´í”„ë¼ì¸ì´ ë©ˆì¶”ë¯€ë¡œ try-catch í•„ìˆ˜
            try {
                aiViewModel.onGestureDetected(result)
                latestGestureResult = result
                gestureAppliedRotation = lastSentRotation
            } catch (e: Exception) {
                Log.e("CameraPage", "ViewModel ì „ë‹¬ ì¤‘ ì—ëŸ¬: ${e.message}")
            }
        }
    }

    val poseLandmarkerHelper = remember {
        PoseLandmarkerHelper(context) { result, _, _ ->
            try {
                val isFront = state.lensFacing == LensFacing.FRONT
                humanTrackingManager.onPoseDetected(result, gestureImgW, gestureImgH, lastSentRotation, isFront)
            } catch (e: Exception) {
                Log.e("CameraPage", "Tracking ì „ë‹¬ ì¤‘ ì—ëŸ¬: ${e.message}")
            }
        }
    }

    // ì„¼ì„œ ê¸°ë°˜ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
    val orientationEventListener = remember {
        object : android.view.OrientationEventListener(context) {
            override fun onOrientationChanged(orientation: Int) {
                if (orientation == ORIENTATION_UNKNOWN) return

                // 0, 90, 180, 270ë„ ê·¼ì²˜ë¡œ ê°’ì„ ë³´ì • (ì•½ 45ë„ ê¸°ì¤€ìœ¼ë¡œ ëŠê¸°)
                val newRotation = when (orientation) {
                    in 45..134 -> 270 // í°ì„ ì™¼ìª½ìœ¼ë¡œ ëˆ•í˜ (ë°˜ì‹œê³„)
                    in 135..224 -> 180 // ê±°ê¾¸ë¡œ
                    in 225..314 -> 90  // í°ì„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ëˆ•í˜ (ì‹œê³„)
                    else -> 0          // ì •ë°©í–¥ ì„¸ë¡œ
                }

                if (Imgrotation != newRotation) {
                    Imgrotation = newRotation
                }
            }
        }
    }

    // 260201. ì¶”ê°€-ë°±ìˆ˜ì—° ë Œì¦ˆ ë°©í–¥ì— ë”°ë¥¸ CameraInfoë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ëŠ” ë¡œì§
    // ProcessCameraProviderë¥¼ í†µí•´ í˜„ì¬ í™œì„±í™”ëœ ì¹´ë©”ë¼ì˜ ì •ë³´ë¥¼ ì°¾ìŒ
    val cameraInfo = remember(state.lensFacing) {
        try {
            val provider = androidx.camera.lifecycle.ProcessCameraProvider.getInstance(context).get()
            val selector = if (state.lensFacing == LensFacing.FRONT) androidx.camera.core.CameraSelector.DEFAULT_FRONT_CAMERA
            else androidx.camera.core.CameraSelector.DEFAULT_BACK_CAMERA
            selector.filter(provider.availableCameraInfos).firstOrNull()
        } catch (e: Exception) {
            null
        }
    }

    // 260201. ë°±ìˆ˜ì—° AI ë¶„ì„ ì“°ë ˆë“œ ë° ë¶„ì„ê¸° ìˆ˜ì •
    // Executors.newFixedThreadPool(2) -> Executors.newSingleThreadExecutor()
    // ë¶„ì„ ìŠ¤ë ˆë“œ 1ê°œë§Œ ì‚¬ìš©, íƒ€ì„ìŠ¤íƒ¬í”„ ì—­ì „ìœ¼ë¡œ ì¸í•œ MediaPipe ë¶„ì„ ì¤‘ë‹¨ ë°©ì§€
    // mediapipeëŠ” íƒ€ì„ì´ ìˆœì°¨ì ìœ¼ë¡œ ì°í˜€ì•¼ë§Œ ë¶„ì„ì„ ì§„í–‰
    val analysisExecutor = remember { Executors.newSingleThreadExecutor() }

    // ì´ë¯¸ì§€ ë¶„ì„ê¸°
    @OptIn(ExperimentalCamera2Interop::class) // Camera2 ì •ë³´ ì ‘ê·¼ì„ ìœ„í•´ í•„ìš”
    val imageAnalyzer = remember {
        ImageAnalysis.Builder()
            .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
            .build()
            .apply {
                // SENSOR_ORIENTATIONì€ í•˜ë“œì›¨ì–´ ê³ ìœ ê°’ì´ë¯€ë¡œ ë¶„ì„ ì‹œì‘ ì „ì— í•œ ë²ˆë§Œ ê°€ì ¸ì˜´
                val sensorOrientation = cameraInfo?.let {
                    Camera2CameraInfo.from(it).getCameraCharacteristic(CameraCharacteristics.SENSOR_ORIENTATION)
                } ?: 90

                // setAnalyzer: ë“¤ì–´ì˜¤ëŠ” í”„ë ˆì„ë§ˆë‹¤ ë¶„ì„ ë¡œì§ì„ ì‹¤í–‰ì‹œí‚¬ ê°ì²´
                setAnalyzer(analysisExecutor) { imageProxy ->
                    // ë…¹í™” ì¤‘ì´ ì•„ë‹ˆë©´ ê¸°ëŠ¥ OFF -> ì—°ì‚° ìì› ë³´í˜¸
                    if (!isRecordingState.value) {
                        // imageProxy: ì¹´ë©”ë¼ ë Œì¦ˆë¥¼ í†µí•´ ë“¤ì–´ì˜¨ ì´ë¯¸ì§€ ë°ì´í„°ì˜ ì •ë³´(í”½ì…€, íšŒì „ ê°ë„, ì‹œê°„ ì •ë³´ ë“±)ì„ ë‹´ì€ ê°ì²´
                        // ë¶„ì„ í›„ë‚˜ ì“°ì´ì§€ ì•Šì„ ë•Œ close() ì•ˆí•´ì£¼ë©´ ì¹´ë©”ë¼ëŠ” ë‹¤ìŒ í”„ë ˆì„ ì•ˆì°ê³  ê¸°ë‹¤ë¦¬ê²Œë¨ -> ì¹´ë©”ë¼ í”„ë¦¬ì§• ì›ì¸
                        imageProxy.close()
                        return@setAnalyzer
                    }

                    // ë¹„íŠ¸ë§µ ì°¸ì¡° ë³€ìˆ˜ ì„ ì–¸
                    // ì•„ì§ Bitmap ìƒì„± X -> toBitmap() í˜¸ì¶œí•´ì•¼ ìƒì„±
                    // ì–´ë–¤ error ìƒí™©ì—ì„œ finally ë¸”ë¡ì—ì„œ recycle() í˜¸ì¶œ, ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
                    var originalBitmap: Bitmap? = null
                    var bitmapToProcess: Bitmap? = null

                    try {
                        originalBitmap = imageProxy.toBitmap()
//                        saveBitmapForDebug(context, originalBitmap!!, "original")

                        // AI ëª¨ë¸ì´ í•™ìŠµí•œ ì´ë¯¸ì§€ì´ì, ì‹¤ì œ ì‚¬ìš©ìê°€ ë³´ê³  ìˆëŠ” í™”ë©´ì— ë§ì¶°ì„œ íšŒì „
                        // ì„¼ì„œê°€ ëŒì•„ê°„ ìƒíƒœë¡œ ë‚´ì¥ë˜ì–´ ìˆì–´ì„œ originalBitmap ìì²´ê°€ ëŒì•„ê°€ì„œ ì¶œë ¥ë˜ê¸° ë•Œë¬¸
                        val targetRotation = (sensorOrientation - Imgrotation + 360) % 360

                        // ê°ë„ì— ë§ëŠ” ìƒˆë¡œìš´ ë¹„íŠ¸ë§µ ìƒì„±
                        val matrix = Matrix().apply { postRotate(targetRotation.toFloat())}
                        bitmapToProcess = Bitmap.createBitmap(
                            originalBitmap, 0, 0, originalBitmap.width, originalBitmap.height, matrix, true
                        )
//                        saveBitmapForDebug(context, bitmapToProcess!!, "processed")

                        // ì‚¬ìš©ì´ ëë‚œ ì›ë³¸ ë¹„íŠ¸ë§µ ì¦‰ì‹œ í•´ì œ (LOS ë©”ëª¨ë¦¬ í­ë°œ ë°©ì§€)
                        // íšŒì „í•œ bitmapToProcessë§Œ ì“¸ ê²ƒì´ë¯€ë¡œ ë°”ë¡œ í•´ì œ
                        originalBitmap.recycle()
                        originalBitmap = null

                        // ì‹œê°í™”ìš© ì‚¬ì´ì¦ˆ ì—…ë°ì´íŠ¸
                        // MediapipeëŠ” ì¢Œí‘œë¥¼ 0.0 ~ 1.0 ì‚¬ì´ì˜ ë¹„ìœ¨ ê°’ìœ¼ë¡œ ë³´ë‚´ì£¼ë¯€ë¡œ ì‹¤ì œ í™”ë©´ì— ë§ì¶”ê¸° ìœ„í•œ ë„ˆë¹„, ë†’ì´ ì—…ë°ì´íŠ¸
                        gestureImgW = bitmapToProcess.width
                        gestureImgH = bitmapToProcess.height

                        // ë¹„íŠ¸ë§µ ìì²´ íšŒì „ ì œê±°, í˜„ì¬ ê°ë„ë§Œ ë³´ëƒ„
                        lastSentRotation = Imgrotation // ë˜‘ë°”ë¡œ ì„¸ì› ì„ ë•Œ 0ë„, ë°˜ì‹œê³„ ë°©í–¥ íšŒì „ 90, 180, 270

                        // ë™ì¼í•œ ë¹„íŠ¸ë§µ ê³µìœ 
                        gestureRecognizerHelper.recognizeBitmap(bitmapToProcess)
                        poseLandmarkerHelper.recognizeBitmap(bitmapToProcess)
                    }
                    catch (e: Exception) {
                        Log.e("CameraPage", "ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: ${e.message}")
                    }
                    finally {
                        // ì‚¬ìš© ì™„ë£Œëœ ë¹„íŠ¸ë§µ ëª…ì‹œì  í•´ì œ ë° ì¹´ë©”ë¼ í•´ë°©
                        bitmapToProcess?.recycle()
                        originalBitmap?.recycle()
                        imageProxy.close()
                    }
                }
            }
    }

    LaunchedEffect(Unit) { humanTrackingManager.connectBluetooth() }
    DisposableEffect(Unit) {
        orientationEventListener.enable() // ë¦¬ìŠ¤ë„ˆ ì‹œì‘
        onDispose {
            gestureRecognizerHelper.clear()
            poseLandmarkerHelper.clear()
            aiViewModel.reset()
            humanTrackingManager.reset()
            analysisExecutor.shutdown()
            orientationEventListener.disable() // ë¦¬ìŠ¤ë„ˆ ì¢…ë£Œ
        }
    }

    val permissionLauncher = rememberLauncherForActivityResult(
        ActivityResultContracts.RequestMultiplePermissions()
    ) {
        hasCameraPermission = it[Manifest.permission.CAMERA] == true
        hasAudioPermission = it[Manifest.permission.RECORD_AUDIO] == true
    }
    LaunchedEffect(Unit) {
        permissionLauncher.launch(arrayOf(Manifest.permission.CAMERA, Manifest.permission.RECORD_AUDIO))
    }

    Scaffold(
        modifier = modifier.fillMaxSize(),
        contentWindowInsets = WindowInsets.navigationBars,
        bottomBar = {
            MainBottomBar(
                currentRoute = "camera",
                onNavigate = { route ->
                    if (route != "camera") navController.navigate(route) {
                        popUpTo("gesture_home") { saveState = true }
                        launchSingleTop = true
                        restoreState = true
                    }
                },
                uiRotation = uiRotation // ì—¬ê¸°ì„œ ê°ë„ë¥¼ ë„˜ê²¨ì¤Œ
            )
        }
    ) { innerPadding ->
        Box(
            modifier = Modifier
                .fillMaxSize()
                .padding(innerPadding)
                // í•€ì¹˜ ì¤Œ ë°œìƒ ì‹œ -> triggerRuler() í˜¸ì¶œí•˜ì—¬ ë£°ëŸ¬ ì¼œê¸°
                .pointerInput(Unit) {
                    detectTransformGestures { _, _, zoom, _ ->
                        cameraViewModel.onIntent(CameraIntent.OnZoomPinch(zoom))
                        triggerRuler()
                    }
                },
            contentAlignment = Alignment.BottomCenter
        ) {
            if (hasCameraPermission) {
                CameraPreview(
                    modifier = Modifier.fillMaxSize(),
                    lensFacing = state.lensFacing,
                    zoomRatio = state.targetZoom,
                    recorderController = recorderController,
                    imageAnalysis = imageAnalyzer,
                    onZoomBoundsReady = { l, min, max, c -> cameraViewModel.onIntent(CameraIntent.OnZoomBoundsReady(l, min, max, c)) },
                    onAppliedZoomChanged = { cameraViewModel.onIntent(CameraIntent.OnAppliedZoomChanged(it)) },
                    onRecordingFinalize = { cameraViewModel.onIntent(CameraIntent.OnRecordingFinalize) },
                    onVideoSaved = { cameraViewModel.onIntent(CameraIntent.OnVideoSaved(it)) },
                    onRecordingError = { cameraViewModel.onIntent(CameraIntent.OnRecordingError(it)) }
                )

                AndroidView(
                    factory = { ctx -> OverlayView(ctx, null) },
                    modifier = Modifier.fillMaxSize(),
                    update = { view ->
                        latestGestureResult?.let {
                            val isFront = state.lensFacing == LensFacing.FRONT
                            view.setResults(it, isFront, gestureImgW, gestureImgH, gestureAppliedRotation)
//                            view.setResults(it, isFront, gestureImgW, gestureImgH, gestureAppliedRotation, gestureRotatedImgW, gestureRotatedImgH)
                        }
                    }
                )
                AndroidView(
                    factory = { ctx -> TrackingOverlayView(ctx, null) },
                    modifier = Modifier.fillMaxSize(),
                    update = { view ->
                        val isFront = state.lensFacing == LensFacing.FRONT
                        view.setResults(trackingState, isFront, Imgrotation)
                    }
                )
            }

            CameraControlsBar(
                isRecording = state.isRecording,
                currentLens = state.lensFacing,
                selectedZoom = state.targetZoom,
                minZoom = state.minZoom,
                maxZoom = state.maxZoom,
                // UI íšŒì „ ê°ì§€
                uiRotation = uiRotation,

                // ìƒíƒœ ë° ì½œë°± ì „ë‹¬
                showRuler = showRuler,
                onRulerInteraction = { triggerRuler() },
                onRequestShowRuler = { triggerRuler() },
                onSwitchLens = { cameraViewModel.onIntent(CameraIntent.OnSwitchLens) },
                onSelectZoom = { cameraViewModel.onIntent(CameraIntent.OnSelectZoom(it)) },
                onToggleRecord = {
                    if (!hasAudioPermission) permissionLauncher.launch(arrayOf(Manifest.permission.RECORD_AUDIO))
                    else if (state.isRecording) {
                        recorderController.stopRecording()
                        cameraViewModel.onIntent(CameraIntent.OnStopRecording)
                    } else {
                        recorderController.startRecording()
                        cameraViewModel.onIntent(CameraIntent.OnStartRecording)
                    }
                },
                modifier = Modifier.padding(bottom = 16.dp),
            )
        }
    }
}

//// [ë°±ìˆ˜ì—°] ë¹„íŠ¸ë§µ ë””ë²„ê¹…ìš© ë‚˜ì¤‘ì— ê¼­ ì§€ìš¸ ê²ƒ
//fun saveBitmapForDebug(context: android.content.Context, bitmap: Bitmap, fileName: String) {
//    val file = File(context.cacheDir, "$fileName.jpg")
//    try {
//        val out = FileOutputStream(file)
//        bitmap.compress(Bitmap.CompressFormat.JPEG, 100, out)
//        out.flush()
//        out.close()
//        Log.d("DebugImage", "ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: ${file.absolutePath}")
//    } catch (e: Exception) {
//        Log.e("DebugImage", "ì €ì¥ ì‹¤íŒ¨: ${e.message}")
//    }
//}